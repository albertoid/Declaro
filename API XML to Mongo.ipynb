{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Revision de XML e integracion en Base de datos en la nube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importación de librearias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "import xmltodict\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import io\n",
    "from os import listdir, remove\n",
    "from os.path import isfile, join\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_folder\n",
    "\n",
    "#Descripción General: Funcion para borrar archivos de la carpeta temporal\n",
    "#Recibe: ruta (path) por default una carpeta temp dentro de la ruta actual\n",
    "#Recibe: lista de archivos (fl)\n",
    "#Regresa: None\n",
    "\n",
    "def clean_folder(fl, path='./temp/'):\n",
    "    for i in fl:\n",
    "        remove(path+i)\n",
    "    \n",
    "    return None\n",
    "\n",
    "#predict_encoding\n",
    "\n",
    "#Descrición general: Predice la codificación de un archivo dado\n",
    "#Recibe: Ruta del Archivo (file_path)\n",
    "#Recibe: Numero de de lineas para la predicción (n_lines) por default 20. Entre mas líneas se mejora la probabilidad de una mejor preduccion\n",
    "#Entrega: Predicción de codificación en un str\n",
    "\n",
    "def predict_encoding(file_path, n_lines=20):\n",
    "    '''Predict a file's encoding using chardet'''\n",
    "    import chardet\n",
    "\n",
    "    # Open the file as binary data\n",
    "    with open(file_path, 'rb') as f:\n",
    "        # Join binary lines for specified number of lines\n",
    "        rawdata = b''.join([f.readline() for _ in range(n_lines)])\n",
    "\n",
    "    return chardet.detect(rawdata)['encoding']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ingreso de datos del usuario para la utilización del módulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ingreso del RFC e ID del usuario\n",
    "#rfc_usuario = input('Ingrese su el rfc del usuario')\n",
    "#id_usuario = input('Ingrese su el id del usuario')\n",
    "\n",
    "rfc_usuario ='IADA810218HG5'\n",
    "id_usuario = 'albertoid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extracción de parámetros de los archivos XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de directorio y generacion de lista de facturas a analizar\n",
    "\n",
    "filespath='./temp/'\n",
    "fileslist = [f for f in listdir(filespath) if isfile(join(filespath, f))]\n",
    "\n",
    "\n",
    "for i in fileslist:\n",
    "    if i[-3:]!=\"xml\":\n",
    "        fileslist.remove(i)\n",
    "\n",
    "\n",
    "for k,z in tqdm(enumerate(fileslist)): \n",
    "    #Opening File\n",
    "    xml=open('./temp/'+z,'r')#,encoding=predict_encoding('./temp/'+z))\n",
    "    xml_parsed=xmltodict.parse(xml.read())\n",
    "        \n",
    "    #Extending XML\n",
    "    xml_keys=list(xml_parsed['cfdi:Comprobante'].keys())\n",
    "    xml_values=list(xml_parsed['cfdi:Comprobante'].values())\n",
    "    xml_df=pd.DataFrame(xml_values).T\n",
    "    xml_df.columns=xml_keys\n",
    "\n",
    "    #Descartando columnas no útiles (por el momento)\n",
    "    columnas=['@xmlns:cfdi','@xmlns:xsi','@Certificado','@xsi:schemaLocation','@Sello']\n",
    "    for i in columnas:\n",
    "        try:\n",
    "            xml_df.drop([i],axis=1,inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #Elementos para hacer sub-despliegue\n",
    "    list_sub=['cfdi:Emisor','cfdi:Receptor'] #cfdi:Conceptos tiene una estructura  de mas grandos de profundidad\n",
    "\n",
    "    #Sub-despliegue de elementos en list_sub\n",
    "    for i in list_sub:\n",
    "        for j in list(dict(xml_df[i][0]).keys()):\n",
    "            xml_df[i+'_'+j] = xml_df[i][0][j]\n",
    "            \n",
    "            \n",
    "    #Desplegar elementos con doble profundidad\n",
    "    complemento='cfdi:Complemento'\n",
    "    timbre='tfd:TimbreFiscalDigital'\n",
    "        \n",
    "    for i in list(dict(xml_df[[complemento]].values[0][0][timbre]).keys()):\n",
    "        xml_df['tfd_'+i] = xml_df[[complemento]].values[0][0][timbre][i]\n",
    "    \n",
    "\n",
    "    #Quitar columnas con diccionarios de sub-despliegue\n",
    "    xml_df.drop(['cfdi:Emisor','cfdi:Receptor','cfdi:Complemento'],axis=1,inplace=True)\n",
    "    \n",
    "\n",
    "    #Limpiar nombres columna\n",
    "    for i,e in enumerate(xml_df.columns):\n",
    "        xml_df.rename(columns={str(e):str(e).replace('cfdi:','')},inplace=True)\n",
    "    for i,e in enumerate(xml_df.columns):\n",
    "        xml_df.rename(columns={str(e):str(e).replace('@','')},inplace=True)\n",
    "    for i,e in enumerate(xml_df.columns):\n",
    "        xml_df.rename(columns={str(e):str(e).lower()},inplace=True)\n",
    "    \n",
    "\n",
    "    #Optimizar tipos de datos\n",
    "    xml_df.fecha[0] = datetime.strptime(xml_df.fecha[0], '%Y-%m-%dT%H:%M:%S')\n",
    "    xml_df.fecha\n",
    "    \n",
    "    '''#Se elimina la optimización, pues mongo no acepta datos optimizados con métodos de numpy\n",
    "    for i in xml_df.columns:    \n",
    "        try:\n",
    "            xml_df[i] = pd.to_numeric(xml_df[i])\n",
    "\n",
    "            if type(xml_df[i])==float:\n",
    "                xml_df[i] = pd.to_numeric(xml_df[i], downcast='float')\n",
    "            elif type(xml_df[i])==int:\n",
    "                xml_df[i] = pd.to_numeric(xml_df[i], downcast='int')\n",
    "        except:\n",
    "            pass\n",
    "    '''\n",
    "    \n",
    "    #Ingreso de identificadores\n",
    "    \n",
    "    xml_df['ingreso']= False if rfc_usuario==xml_df.receptor_rfc[0] else True\n",
    "    xml_df['usuario']= id_usuario\n",
    "    xml_df['rfc_usuario']=rfc_usuario\n",
    "    \n",
    "    #Ingresar xml completo como respaldo\n",
    "    #xml_df['xml']=xml_txt\n",
    "    \n",
    "    #Cerrar archivo\n",
    "    xml.close()\n",
    "    \n",
    "    #Integracion de la base de datos final\n",
    "    if k == 0: \n",
    "        df_xml = xml_df #Crea base de datos de salida en la primera iteracion\n",
    "    else:\n",
    "        columnas_nuevas = list(xml_df.columns)\n",
    "        columnas_existentes = list(df_xml.columns)\n",
    "        \n",
    "        #Busca columnas nuevas en el nuevo registro y crea la columna correspondiente\n",
    "        for e in columnas_existentes:\n",
    "            try:\n",
    "                columnas_nuevas=columnas_nuevas.remove(e)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        try:\n",
    "            for e in columnas_nuevas:\n",
    "                df_xml[e] = df_xml[e].apply(lambda x: None)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        #copia la columna anterior con las nuevas columnas\n",
    "        df_xml=df_xml.append(df_xml.iloc[0],ignore_index=True)\n",
    "        \n",
    "        #Ingreso de los registros uno a uno en donde pueden no existir todos los campos en el nuevo registro \n",
    "        columnas=df_xml.columns\n",
    "        \n",
    "        for i in columnas:\n",
    "            try:\n",
    "                df_xml[i].iloc[-1] = xml_df[i][0]\n",
    "            except:\n",
    "                df_xml[i].iloc[-1] = None\n",
    "\n",
    "dict_xml=df_xml.to_dict('records')\n",
    "\n",
    "#----------------------------Ingreso de datos en la base de datos de Mongo en la nube----------------------------\n",
    "\n",
    "pwd=open('pw.txt','r')\n",
    "pw=pwd.read()\n",
    "cliente=MongoClient('mongodb+srv://api:'+pw.split('\\n')[0]+'@clusterdeclaro-tya5c.mongodb.net/test?retryWrites=true&w=majority')\n",
    "db_api=cliente.api\n",
    "col_facturas=db_api.facturas\n",
    "\n",
    "#Ingreso de facturas a Mongo\n",
    "col_facturas.insert_many(dict_xml);\n",
    "\n",
    "#------------------------------------Eliminación de los archivos XML---------------------------------------------\n",
    "\n",
    "#Borrar archivos de temp\n",
    "fileslist = [f for f in listdir(filespath) if isfile(join(filespath, f))]\n",
    "clean_folder(fl=fileslist)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
